"""
Modified from the Pyimagesearch 5-part series on Siamese networks: https://pyimg.co/dq1w5
"""

# Standard Library imports
from pathlib import Path

# External imports
import tensorflow as tf


# Data paths
DATASET = Path(r"<<FILL ME>>")
DATASET_SUBSET = Path(r"<<FILL ME>>")
TRAIN_DATASET = DATASET / "train"
VALID_DATASET = DATASET / "val"

QUERY_DATASET = Path(r"<<FILL ME>>")

# Model input image size
IMAGE_SIZE = (<<FILL ME>>, <<FILL ME>>)

AUTO = tf.data.AUTOTUNE

# Number of features of the embedding generated by the backbone
EMBEDDING_SHAPE = 128  # Densenet121

# Training parameters
TRAIN_BACKBONE = False
LEARNING_RATE = 1e-2
INITIAL_EPOCH = 0
INITIAL_VALUE_THRESH = None  # Set to None if first training
EPOCHS = 100
BATCH_SIZE = 4
NUM_TRAIN_SAMPLES = <<FILL ME>>
NUM_VALIDATION_SAMPLES = <<FILL ME>>
STEPS_PER_EPOCH = int(NUM_TRAIN_SAMPLES / BATCH_SIZE)
VALIDATION_STEPS = int(NUM_VALIDATION_SAMPLES / BATCH_SIZE)

# Inference parameters
N_RESULTS = 9

# Index parameters
INDEX_TYPE = "dict"  # faiss, dict

# Output paths
OUTPUT_PATH = Path("siamese_output", "densenet121")
LOAD_MODEL_PATH = OUTPUT_PATH / "not_existent.keras"  # Used for loading, if exists
MODEL_CKPT_PATH = OUTPUT_PATH / "epoch_{epoch:02d}-loss_{val_loss:.4f}.keras"
FAISS_INDEX_PATH = OUTPUT_PATH / "index.faiss"
MANUAL_INDEX_PATH = OUTPUT_PATH / "index.pickle"
LOGS_PATH = OUTPUT_PATH / "logs"
IMAGES_DF_PATH = OUTPUT_PATH / "images.csv"
